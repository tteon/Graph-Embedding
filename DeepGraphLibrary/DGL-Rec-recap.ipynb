{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source ; https://github.com/dglai/WWW20-Hands-on-Tutorial/blob/master/_legacy/advanced_apps/rec/Recommendation.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem setting\n",
    "\n",
    "In this tutorial, we demonstarte how graph neural networks can be used for recommendtaion. Here we focus on item-based recommendtaion model. This method in this tutorial recommends items that are similar to the ones purchased by the user. We demonstrate the recommendation model on the MovieLens dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get started\n",
    "\n",
    "DGL can be used with different deep learning frameworks. Currently, DGL can be used with Pytorch and MXNet. Here, we show how DGL works wtih Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we load DGL. we need to set the DGL backend for one of the deep learning frameworks. Because this tutorial develops meodels in Pytorch, we have to set the DGL backend to Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "\n",
    "# Load Pytorch as backend\n",
    "dgl.load_backend('pytorch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the rest of necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy import sparse as spsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We use the MovieLens dataset for demonstration because it is commonly used for ecommendation models. in this dataset, there are two types of nodes; users and movies . The movie nodes have three attributes ; year, title and genre. There are ratings between user models and movie does. Each rating has a timestamp. In our recommendation model, we don't consider ratings and timestamps.\n",
    "\n",
    "__Note:__ It is not necessarily the best dataset to demonstarate the power of GNN for recommendation. We have prepared the dataset simplify the demonstartion.\n",
    "\n",
    "To run the data preprocessing script, a user nedds to download the English dictionary of the standfordnlp package first,However, the following command only needs to run once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Default download directory: /home/tteon/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: /home/tteon/stanfordnlp_resources/en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235M/235M [05:18<00:00, 737kB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: /home/tteon/stanfordnlp_resources/en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "stanfordnlp.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found. Downloading from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/movielens.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/3702 [00:00<01:23, 44.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/home/tteon/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/home/tteon/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "Done loading processors!\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3702/3702 [00:45<00:00, 81.18it/s] \n",
      "100%|██████████| 3702/3702 [00:00<00:00, 80509.13it/s]\n",
      "/home/tteon/anaconda3/lib/python3.7/site-packages/pandas/core/series.py:942: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self.loc[key]\n"
     ]
    }
   ],
   "source": [
    "from movielens import MovieLens\n",
    "data = MovieLens('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = data.ratings\n",
    "user_id = np.array(ratings['user_idx'])\n",
    "movie_id = np.array(ratings['movie_idx'])\n",
    "user_movie_spm = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "num_users, num_movies = user_movie_spm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#user-movie iterations: 1000205\n",
      "#users: 6040\n",
      "#movies: 3702\n"
     ]
    }
   ],
   "source": [
    "print('#user-movie iterations:', len(movie_id))\n",
    "print('#users:', num_users)\n",
    "print('#movies:', num_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the dataset into a training set and a testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_train = ratings[~(ratings['valid_mask'] | ratings['test_mask'])]\n",
    "user_latest_item_indices = (ratings_train.groupby('user_id')['timestamp'].transform(pd.Series.max)==ratings_train['timestamp'])\n",
    "user_latest_item = ratings_train[user_latest_item_indices]\n",
    "user_latest_item = dict(zip(user_latest_item['user_idx'].values, user_latest_item['movie_idx'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the training, validation and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#training size: 986669\n"
     ]
    }
   ],
   "source": [
    "# The traning dataset\n",
    "user_id = np.array(ratings_train['user_idx'])\n",
    "movie_id = np.array(ratings_train['movie_idx'])\n",
    "user_movie_sam = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "assert num_users == user_movie_spm.shape[0]\n",
    "assert num_movies == user_movie_spm.shape[1]\n",
    "train_size = len(user_id)\n",
    "print('#training size:', train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation and testing dataset\n",
    "users_valid = ratings[ratings['valid_mask']]['user_idx'].values\n",
    "movies_valid = ratings[ratings['valid_mask']]['movie_idx'].values\n",
    "users_test = ratings[ratings['test_mask']]['user_idx'].values\n",
    "movies_test = ratings[ratings['test_mask']]['movie_idx'].values\n",
    "valid_size = len(users_valid)\n",
    "test_size = len(users_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The recommendation model\n",
    "\n",
    "At large, the model first learns item embeddings from the user-item interation dataset and use the item embeddings to recommend users similar items they have purchased. To learn item embeddings, we first need to construct an item similarity graph and train GNN on the item graph.\n",
    "\n",
    "There are many ways of constructing the item similarity graph. Here we use the __SLIM MODEL__ to learn item similarity and use the learned result to construct the item graph. The resulting graph will have an edge between two items if they are similar and the edge has a weight that represents the simlilarity score.\n",
    "\n",
    "After the item similarity graph is consturcted, we run a GNN model on it and use the vertex connectivity as the training singnal to train the GNN model. The GNN training procedure is very similar to the link predction task in the precious section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consturct the movie graph with SLIM\n",
    "\n",
    "SLIM is an item-based recommendation model. when training SLIM on a user-item dataset, it learns an item similarity graph. This similarity graph is the imtem graph we construct for the GNN model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SLIM import SLIM, SLIMatrix\n",
    "from slim_load import read_csr\n",
    "\n",
    "def gen_slim_graph(user_movie_spm):\n",
    "    model = SLIM()\n",
    "    params = {'algo': 'cd', 'nthreads': 2, 'l1r': 1.0 , 'l2r' : 1.0}\n",
    "    trainmat = SLIMatrix(user_movie_spm.tocsr())\n",
    "    model.train(params, trainmat)\n",
    "    model.save_model(modelfname='slim_model.csr', mapfname='slim_map.csr')\n",
    "    \n",
    "    #Load the sLIM similarity matrix into DGL. we store the vertex similarity as edge data on DGL.\n",
    "    movie_spm = read_csr('slim_model.csr')\n",
    "    print('#edges:', movie_spm.nnz)\n",
    "    print('most similar:', np.max(movie_spm.data))\n",
    "    print('most unsimilar:', np.min(movie_spm.data))\n",
    "    \n",
    "    # GEnerate DGLGraph\n",
    "    g = dgl.DGLGraph(movie_spm, readonly=True)\n",
    "    g.edata['similarity'] = torch.tensor(movie_spm.data, dtype=torch.float32)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the co-occurance graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample_factor = 1e-6\n",
    "\n",
    "def gen_cooccur_graph(user_movie_spm):\n",
    "    user_id = user_movie_spm.row\n",
    "    movie_id = user_movie_spm.col\n",
    "    spm_t = user_movie_spm.transpose()\n",
    "    movie_deg = spm_t.dot(np.ones((num_users,)))\n",
    "    movie_ratio = movie_deg / np.sum(movie_deg)\n",
    "    # 1e-6 is a hyperparameter for this dataset.\n",
    "    movie_sample_prob = 1 - np.maximum(1 - np.sqrt(downsample_factor / movie_ratio), 0)\n",
    "    sample_prob = movie_sample_prob[movie_id]\n",
    "    sample = np.random.uniform(size=(len(movie_id),))\n",
    "    user_id = user_id[sample_prob > sample]\n",
    "    movie_id = movie_id[sample_prob > sample]\n",
    "    print('#samples:', len(user_id))\n",
    "    user_movie_spm = spsp.coo_matrix((np.ones((len(user_id),)), (user_id, movie_id)))\n",
    "    print(user_movie_spm.shape)\n",
    "    movie_deg = spm_t.dot(np.ones((num_users,)))\n",
    "    print(np.sum(movie_deg == 0))\n",
    "    \n",
    "    movie_spm = np.dot(user_movie_spm.transpose(), user_movie_spm)\n",
    "    #dense_movie = np.sort(movie_spm.todense())\n",
    "    #topk_movie = dense_movie[:,-50]\n",
    "    #movie_spm1 = movie_spm >= topk_movie\n",
    "    \n",
    "    g = dgl.DGLGraph(movie_spm, readonly=True)\n",
    "    g.edata['similarity'] = torch.tensor(movie_spm.data, dtype=torch.float32)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "topk = 20\n",
    "def gen_cosine_graph(user_movie_spm):\n",
    "    movie_spm = cosine_similarity(user_movie_spm.transpose(),dense_output=False)\n",
    "    \n",
    "    dense_movie = np.sort(movie_spm.todense())\n",
    "    topk_movie = dense_movie[:,-topk]\n",
    "    topk_movie_spm = movie_spm > topk_movie\n",
    "    topk_movie_spm = movie_spm.multiply(topk_movie_spm)\n",
    "    g = dgl.DGLGraph(topk_movie_spm, readonly=True)\n",
    "    g.edata['similarity'] = torch.tensor(topk_moive_spm.data, dtype=torch.float32)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate graphs for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning takes 37.576 secs.\n",
      "#edges: 307660\n",
      "most similar: 0.65398\n",
      "most unsimilar: 0.0\n",
      "#samples: 49605\n",
      "(6040, 3702)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "conv_g = gen_slim_graph(user_movie_spm)\n",
    "loss_g = gen_cooccur_graph(user_movie_spm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the item features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#featuers: 4124\n"
     ]
    }
   ],
   "source": [
    "year = np.expand_dims(data.movie_data['year'], axis=1)\n",
    "genre = data.movie_data['genre']\n",
    "title = data.movie_data['title']\n",
    "features = torch.tensor(np.concatenate((genre, title), axis=1), dtype=torch.float32)\n",
    "print('#featuers:', features.shape[1])\n",
    "in_feats = features.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN models\n",
    "\n",
    "We run GNN on the item graph to compute item embeddings. In this tutorial. we use a sustomized __GraphSage__ model to compute node embeddings. The original GraphSaeg performs the following computations on every node v in the graph:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original GraphSage model treats each neighbor equally. However, the SLIM model learns the item similarity based on the user-item iteration. The GNN model should take the similarity into account. Thus, we customize the GraphSage model in the following fashion. Instead of aggregating all neighbors equally, we aggregate neighbors embeddings rescaled by the similarity on the edges. Thus, the aggregation step is defined as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GNN model has multiple layers. Ine ach layers, a vertex accesses its direct neighbors. When we stack k layers in a model, a node v access neighbors within k hops. The output of the GNN model is node embeddings that represent the nodes and all information in the k-hop neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the computation in each layer of the customized GraphSage model in SAGEConv and implement the multi-layer model in GraphSAGEModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sageconv import SAGEConv\n",
    "\n",
    "class GraphSAGEModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 out_dim,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator_type):\n",
    "        super(GraphSAGEModel, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type,\n",
    "                                    feat_drop=dropout, activation=activation))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type,\n",
    "                                        feat_drop=dropout, activation=activation))\n",
    "        # output layer\n",
    "        self.layers.append(SAGEConv(n_hidden, out_dim, aggregator_type,\n",
    "                                    feat_drop=dropout, activation=None))\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        h = features\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h, g.edata['similarity'])\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Item Embeddings\n",
    "\n",
    "we train the item embeddings with the edges in the item graph as the training signal. This step is very similar to the link prediction task in the __basic applications.__\n",
    "\n",
    "Becaues the MovieLens dataset has sparse features (both genre and title are stored as multi-hot encoding). The sparse features have many dimensions. To run GNN on the item features, we first create an encoding layer to project the sparse features to a lower dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodeLayer(nn.Module):\n",
    "    def __init__(self, in_feats, num_hidden):\n",
    "        super(EncodeLayer, self).__init__()\n",
    "        self.proj = nn.Linear(in_feats, num_hidden)\n",
    "        \n",
    "    def forward(self, feats):\n",
    "        return self.proj(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first use GraphSage as the base model to compute node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "n_hidden = 64\n",
    "n_layers = 1\n",
    "dropout = 0.5\n",
    "aggregator_type = 'sum'\n",
    "\n",
    "# create GraphSAGE model\n",
    "gconv_model = GraphSAGEModel(n_hidden,\n",
    "                            n_hidden,\n",
    "                            n_hidden,\n",
    "                            n_layers,\n",
    "                            F.relu,\n",
    "                            dropout,\n",
    "                            aggregator_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply use node connectivity as the training signal :nodes connected by edges are similar, while nodes not connected by edges are dissimilar.\n",
    "\n",
    "To train such a model, we need to deploy negative sampling to construct negative samples. A positive sample is an edge that exist in the original graph, while a negative sample is a pair of nodes that don't have an edge between them in the graph. We usually train on each positive sample with multiple negative samples.\n",
    "\n",
    "After having the node embeddings, we compute the similarity scores on positive samples and negative samples. WE construct the following loss function on a positive sample and the corresponding negative samples:\n",
    "\n",
    "With this loss, training should increase the simliarity scores on the positive samples and decrease the similarity scores on negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NCE loss\n",
    "def NCE_loss(pos_score, neg_score, neg_sample_size):\n",
    "    pos_score = F.logsigmoid(pos_score)\n",
    "    neg_score = F.logsigmoid(-neg_score).reshape(-1, neg_sample_size)\n",
    "    return -pos_score - torch.sum(neg_score, dim=1)\n",
    "\n",
    "class GNNRec(nn.Module):\n",
    "    def __init__(self, gconv_model):\n",
    "        super(GNNRec, self).__init__()\n",
    "        self.encode = EncodeLayer(in_feats, n_hidden)\n",
    "        self.gconv_model = gconv_model\n",
    "        \n",
    "    def forward(self, conv_g, loss_g, features, neg_sample_size):\n",
    "        emb = self.encode(features)\n",
    "        emb = self.gconv_model(conv_g, emb)\n",
    "        pos_g, neg_g = edge_sampler(loss_g, neg_sample_size, return_false_neg=False)\n",
    "        pos_score = score_func(pos_g, emb)\n",
    "        neg_score = score_func(neg_g, emb)\n",
    "        return torch.mean(NCE_loss(pos_score, neg_score, neg_sample_size) * pos_g.edata['weight'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGL provides an edge sampler EdgeSampler, which selects positive edge samples and negative edge samples efficiently. Thus, we can use it to generate positive samples and negative samples for link prediction. EdgeSampler generates neg_sample_size negative edges by corrupting the head or the tail node of a positive edge with some randomly sampled nodes.\n",
    "\n",
    "edge_sampler samples one tenth of the edges in the graph as positive edges. It reutrns a positive subgraph and a negative subgraph. The positivie subgraph contains all positive edges sampled from the graph g, while the negative subgraph contains all negative edges contructed by the edge sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_sampler(g, neg_sample_size, edges=None, return_false_neg=True):\n",
    "    sampler = dgl.contrib.sampling.EdgeSampler(g, batch_size=int(g.number_of_edges()/10), seed_edges = edges, neg_sample_size = neg_sample_size,\n",
    "                                              negative_mode='tail',\n",
    "                                               shuffle=True,\n",
    "                                              return_false_neg=return_false_neg)\n",
    "    sampler = iter(sampler)\n",
    "    pos_subg, neg_subg = next(sampler)\n",
    "    pos_subg.edata['weight'] = g.edata['similarity'][pos_subg.parent_eid]\n",
    "    return pos_subg, neg_subg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the positive edge subgraph and the negative edge subgraph, we can now compute the similarity on the positive edge samples and negative edge samples.\n",
    "\n",
    "In this tutorial, we use dot-product similarity to measure the similarity between two nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(g, emb):\n",
    "    src_nid, dst_nid = g.all_edges(order='eid')\n",
    "    # Get the node Ids in the parent graph.\n",
    "    src_nid = g.parent_nid[src_nid]\n",
    "    dst_nid = g.parent_nid[dst_nid]\n",
    "    # Read the node embeddings of the source nodes and destination nodes.\n",
    "    pos_heads = emb[src_nid]\n",
    "    pos_tails = emb[dst_nid]\n",
    "    # cosine similarity\n",
    "    return torch.sum(pos_heads * pos_tails, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the performance of the trained item embeddings in the item-based recommendation task. We use the last item that a user purchased to represent the user and compute the similarity between the last item and a list of item( a item the user will purchase and a set of randomly sampled items). We calculate the ranking of the item that will be purchased among the list of items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RecEvaluate(model, g, features, users_eval, movies_eval, neg_sample_size):\n",
    "    gconv_model.eval()\n",
    "    with torch.no_grad():\n",
    "        emb = model.encode(features)\n",
    "        emb = model.gconv_model(g, emb)\n",
    "        hits_10s = []\n",
    "        # evaluate one user-item interaction at a time\n",
    "        for u, i in zip(users_eval, movies_eval):\n",
    "            I_q = user_latest_item[u]\n",
    "            I = torch.cat([torch.LongTensor([i]), torch.LongTensor(data.neg_valid[u])])\n",
    "            Z_q = emb[I_q]\n",
    "            Z = emb[I]\n",
    "            score = (Z_q[None, :] * Z).sum(1).cpu().numpy()\n",
    "            rank = stats.rankdata(-score, 'min')\n",
    "            hits_10s.append(rank[0] <= 10)\n",
    "        print('HITS@10:{:.4f}'.format(np.mean(hits_10s)))\n",
    "        return np.mean(hits_10s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 94.8204\n",
      "HITS@10:0.2932\n",
      "Epoch 00001 | Loss 65.5102\n",
      "HITS@10:0.2718\n",
      "Epoch 00002 | Loss 50.8380\n",
      "HITS@10:0.2934\n",
      "Epoch 00003 | Loss 45.4391\n",
      "HITS@10:0.3114\n",
      "Epoch 00004 | Loss 42.8007\n",
      "HITS@10:0.3142\n",
      "Epoch 00005 | Loss 40.1818\n",
      "HITS@10:0.3141\n",
      "Epoch 00006 | Loss 38.4314\n",
      "HITS@10:0.3230\n",
      "Epoch 00007 | Loss 37.4669\n",
      "HITS@10:0.3405\n",
      "Epoch 00008 | Loss 36.6479\n",
      "HITS@10:0.3460\n",
      "Epoch 00009 | Loss 36.3470\n",
      "HITS@10:0.3420\n",
      "\n",
      "HITS@10:0.4075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4074832464631422"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model for link prediction\n",
    "model = GNNRec(gconv_model)\n",
    "\n",
    "# Training hyperparameters\n",
    "weight_decay = 5e-4\n",
    "n_epochs = 20\n",
    "lr = 1e-3\n",
    "neg_sample_size = 40\n",
    "\n",
    "# use optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# initialize graph\n",
    "dur = []\n",
    "prev_acc = 0\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    loss = model(conv_g, loss_g, features, neg_sample_size)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch {:05d} | Loss {:.4f}\".format(epoch, loss.item()))\n",
    "    \n",
    "    acc = RecEvaluate(model, conv_g, features, users_valid, movies_valid, neg_sample_size)\n",
    "    # We have an early stop\n",
    "    if epoch > 8 and acc <= prev_acc:\n",
    "        break\n",
    "    prev_acc = acc\n",
    "    \n",
    "print()\n",
    "# Let's save the trained node embeddings.\n",
    "RecEvaluate(model, conv_g, features, users_test, movies_test, neg_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
